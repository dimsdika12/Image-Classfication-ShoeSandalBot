# -*- coding: utf-8 -*-
"""Image_Classification_ShoeSandalBoot

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14oLrshwMjJg2lyhI0xll7f3AtdTCalwz

[data resourh](https://www.kaggle.com/datasets/hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images) from Kaggle.

Import Dataset
"""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images

"""Unzip Dataset"""

# Extract the zip file
import zipfile, os
local_zip = '/content/shoe-vs-sandal-vs-boot-dataset-15k-images.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/tmp')
zip_ref.close()

"""Define the path for the dataset"""

# Define the path for the dataset
base_dir = '/content/tmp/Shoe vs Sandal vs Boot Dataset'
train_dir = '/content/output/train'
validation_dir = '/content/output/val'

"""Split dataset"""

# Install split-folders (if not already installed)
!pip install split-folders

# Split the dataset into the train and validation sets
import splitfolders
splitfolders.ratio(base_dir, output='output', seed=1337, ratio=(.8, .2), group_prefix=None)

"""Import Library"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import Callback
import numpy as np
import matplotlib.pyplot as plt

"""- Perform image augmentation.
- Prepare training data and evaluation data.
- Label datasets automatically.
"""

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    class_mode='categorical',
                                                    target_size=(150, 150))

validation_datagen = ImageDataGenerator(
    rescale=1.0/255
)
validation_generator = validation_datagen.flow_from_directory(validation_dir,
                                                        class_mode='categorical',
                                                        target_size=(150, 150))

"""Model"""

# Uses pre-trained MobileNetV2 as the base model
pre_trained_model = MobileNetV2(weights="imagenet", include_top=False, input_tensor=Input(shape=(150, 150, 3)))

for layer in pre_trained_model.layers:
    layer.trainable = False

# Takes the last output from the base model
last_output = pre_trained_model.output

# Added Conv2D and MaxPooling2D to existing models
x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(last_output)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten(name="flatten")(x)
x = Dropout(0.3)(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.2)(x)
x = Dense(64, activation="relu")(x)
x = Dense(32, activation="relu")(x)
x = Dense(3, activation='softmax')(x)

# Create a model with a combination of the MobileNetV2 base model and the newly added layers
model = Model(pre_trained_model.input, x)

int_lr = 0.0001
num_epochs = 100

optimizer = tf.optimizers.Adam(lr=int_lr)
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""Train model"""

class MinimumAccuracyCallback(Callback):
    def on_epoch_end(self, epoch, logs={}):
      if(logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92):
        print("\nReached minimum accuracy of 92% on both training and validation sets!")
        self.model.stop_training = True
callback = MinimumAccuracyCallback()
history = model.fit(train_generator,
              epochs=num_epochs,
              validation_data=validation_generator,verbose=2,callbacks=[callback])

"""Make plots of model accuracy and loss."""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

"""Save the model into TF-Lite format"""

import pathlib
# Save the model in SavedModel format
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi shoesandalboot.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('shoesandalboot.tflite')
tflite_model_file.write_bytes(tflite_model)